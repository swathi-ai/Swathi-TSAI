{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"EVA7_S5_Step3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"dabbbd3264f64a6ebac90e07aeb66a80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_71570e1df4024099b1944ee746aac47d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_75577d77743746fdb0110fa4e7569c2d","IPY_MODEL_9d65c975544347a1bf528b01537a467e","IPY_MODEL_578010b7335f4752a6bf44e0dafde929"]}},"71570e1df4024099b1944ee746aac47d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75577d77743746fdb0110fa4e7569c2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f95be0886bcc4aeda96a503e37df62cc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_90c12f6a13ec4ebb9ede98691bf9c472"}},"9d65c975544347a1bf528b01537a467e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d726e170d28b4797a4f4ada9445cee73","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ea2f30453b13417392fc1898fcd68cab"}},"578010b7335f4752a6bf44e0dafde929":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dbf7fc3f79914a1f925e1ee2fa3f2b02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [00:00&lt;00:00, 23875550.26it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6a6127ab7caf41f7a732b6de171ca7fb"}},"f95be0886bcc4aeda96a503e37df62cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"90c12f6a13ec4ebb9ede98691bf9c472":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d726e170d28b4797a4f4ada9445cee73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ea2f30453b13417392fc1898fcd68cab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbf7fc3f79914a1f925e1ee2fa3f2b02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6a6127ab7caf41f7a732b6de171ca7fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3c78f0e8225f4a9c946fae1d3af0b379":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_eb9741f92ec148b2804110befdf97f32","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_297a71a2b7924ac399842a005711ca21","IPY_MODEL_553c793d93cc4ee6a03bf49bfce16d7f","IPY_MODEL_54b4f4a97c4d404482b18717001c07f9"]}},"eb9741f92ec148b2804110befdf97f32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"297a71a2b7924ac399842a005711ca21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9442fa0fe01a4a98b662ca3fa80f8ea1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bdb366b5cd3149e497cb3b6cd3df78d4"}},"553c793d93cc4ee6a03bf49bfce16d7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_74dd433661a04431b4554ff3f0b46a9f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11b2464529af45c79f2be2a19aa283e3"}},"54b4f4a97c4d404482b18717001c07f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_589a282081c249b8b9e53e5cf00ac0e7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:00&lt;00:00, 536112.96it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ff8e5f5f3204754b9ce4ca496cfd523"}},"9442fa0fe01a4a98b662ca3fa80f8ea1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bdb366b5cd3149e497cb3b6cd3df78d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"74dd433661a04431b4554ff3f0b46a9f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"11b2464529af45c79f2be2a19aa283e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"589a282081c249b8b9e53e5cf00ac0e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ff8e5f5f3204754b9ce4ca496cfd523":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a2ee34d39e7d4255b87074982fd1b1be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ca2e2a51c3684414a5c540030b096336","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_713a53c6a2b5435ea47b09cde653f7d5","IPY_MODEL_a4851aeaa52e4296b50fbac50358bd53","IPY_MODEL_908a8693c527493bb10ed34e9a9642fd"]}},"ca2e2a51c3684414a5c540030b096336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"713a53c6a2b5435ea47b09cde653f7d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a19734963779490d938990197fd170e4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b435ea47d5314fe5bc60427489871f92"}},"a4851aeaa52e4296b50fbac50358bd53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_69e9d2f4e95a40e597ddce687f7b81c9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_93319c383779434c8c98c6e14cb9308c"}},"908a8693c527493bb10ed34e9a9642fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b20126679bad48009b3869d2749ab9e8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:00&lt;00:00, 4230800.55it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3a39e8b0f83a4180a8b7b8237b83311b"}},"a19734963779490d938990197fd170e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b435ea47d5314fe5bc60427489871f92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69e9d2f4e95a40e597ddce687f7b81c9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"93319c383779434c8c98c6e14cb9308c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b20126679bad48009b3869d2749ab9e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3a39e8b0f83a4180a8b7b8237b83311b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"17bc715dd01e4a3ca4eca457be4207fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_49310caa0dd540d79ad8689b9a5a90d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8b317f12a75e4e3a8a0ec95880d719de","IPY_MODEL_76df9bc509ef4e6bb9c98c5c0b937ac8","IPY_MODEL_fd096b5d213b41898d9926420c52bdf4"]}},"49310caa0dd540d79ad8689b9a5a90d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b317f12a75e4e3a8a0ec95880d719de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_056af0a42787455ea8754c015ebc0f2b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_941ce36b8bc041ea9d403da5715dbe02"}},"76df9bc509ef4e6bb9c98c5c0b937ac8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76368ed4b736415fa6c75acefc6f0c79","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57ec8ce481f94f289837e076d2cd474f"}},"fd096b5d213b41898d9926420c52bdf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_484d8886faa34864baea14b0d30c823e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:00&lt;00:00, 142404.19it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7320fde70a904ae1ba4a30afe9c1b22e"}},"056af0a42787455ea8754c015ebc0f2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"941ce36b8bc041ea9d403da5715dbe02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76368ed4b736415fa6c75acefc6f0c79":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"57ec8ce481f94f289837e076d2cd474f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"484d8886faa34864baea14b0d30c823e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7320fde70a904ae1ba4a30afe9c1b22e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"j-y3xI1Muy9i"},"source":["**Target:**\n","\n","To improve accuarcy while reducing overfitting by\n","adding Dropout with a value of 0.05\n","\n","**Results:**\n","\n","Parameters: 8K\n","\n","Best Training Accuracy: 99.26\n","\n","Best Test Accuracy: 99.06\n","\n","**Analysis:**\n","\n","No of parameters are ok when compared with the target \n","\n","Model is little over-fitting, hence we will add image augmentation techniques like rotation in next step"]},{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT"},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hIiyxIBsroA"},"source":["# Train Phase transformations\n","train_transforms = transforms.Compose([\n","                                      #  transforms.Resize((28, 28)),\n","                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.1307,), (0.3081,)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n","                                       # Note the difference between (0.1307) and (0.1307,)\n","                                       ])\n","\n","# Test Phase transformations\n","test_transforms = transforms.Compose([\n","                                      #  transforms.Resize((28, 28)),\n","                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.1307,), (0.3081,))\n","                                       ])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465,"referenced_widgets":["dabbbd3264f64a6ebac90e07aeb66a80","71570e1df4024099b1944ee746aac47d","75577d77743746fdb0110fa4e7569c2d","9d65c975544347a1bf528b01537a467e","578010b7335f4752a6bf44e0dafde929","f95be0886bcc4aeda96a503e37df62cc","90c12f6a13ec4ebb9ede98691bf9c472","d726e170d28b4797a4f4ada9445cee73","ea2f30453b13417392fc1898fcd68cab","dbf7fc3f79914a1f925e1ee2fa3f2b02","6a6127ab7caf41f7a732b6de171ca7fb","3c78f0e8225f4a9c946fae1d3af0b379","eb9741f92ec148b2804110befdf97f32","297a71a2b7924ac399842a005711ca21","553c793d93cc4ee6a03bf49bfce16d7f","54b4f4a97c4d404482b18717001c07f9","9442fa0fe01a4a98b662ca3fa80f8ea1","bdb366b5cd3149e497cb3b6cd3df78d4","74dd433661a04431b4554ff3f0b46a9f","11b2464529af45c79f2be2a19aa283e3","589a282081c249b8b9e53e5cf00ac0e7","4ff8e5f5f3204754b9ce4ca496cfd523","a2ee34d39e7d4255b87074982fd1b1be","ca2e2a51c3684414a5c540030b096336","713a53c6a2b5435ea47b09cde653f7d5","a4851aeaa52e4296b50fbac50358bd53","908a8693c527493bb10ed34e9a9642fd","a19734963779490d938990197fd170e4","b435ea47d5314fe5bc60427489871f92","69e9d2f4e95a40e597ddce687f7b81c9","93319c383779434c8c98c6e14cb9308c","b20126679bad48009b3869d2749ab9e8","3a39e8b0f83a4180a8b7b8237b83311b","17bc715dd01e4a3ca4eca457be4207fe","49310caa0dd540d79ad8689b9a5a90d9","8b317f12a75e4e3a8a0ec95880d719de","76df9bc509ef4e6bb9c98c5c0b937ac8","fd096b5d213b41898d9926420c52bdf4","056af0a42787455ea8754c015ebc0f2b","941ce36b8bc041ea9d403da5715dbe02","76368ed4b736415fa6c75acefc6f0c79","57ec8ce481f94f289837e076d2cd474f","484d8886faa34864baea14b0d30c823e","7320fde70a904ae1ba4a30afe9c1b22e"]},"id":"kp-nev_yszs5","executionInfo":{"status":"ok","timestamp":1635157562243,"user_tz":-330,"elapsed":2226,"user":{"displayName":"Rakasi Swati","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07085964486056869501"}},"outputId":"e0029837-9328-4068-e05c-9dd4a16ae21c"},"source":["train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n","test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dabbbd3264f64a6ebac90e07aeb66a80","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/9912422 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3c78f0e8225f4a9c946fae1d3af0b379","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/28881 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2ee34d39e7d4255b87074982fd1b1be","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1648877 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"17bc715dd01e4a3ca4eca457be4207fe","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/4542 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpi3-cDds8SW","executionInfo":{"status":"ok","timestamp":1635157562243,"user_tz":-330,"elapsed":8,"user":{"displayName":"Rakasi Swati","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07085964486056869501"}},"outputId":"f9bc944c-d472-4bd0-b773-5c41364da4fa"},"source":["SEED = 1\n","\n","# CUDA?\n","cuda = torch.cuda.is_available()\n","print(\"CUDA Available?\", cuda)\n","\n","# For reproducibility\n","torch.manual_seed(SEED)\n","\n","if cuda:\n","    torch.cuda.manual_seed(SEED)\n","\n","# dataloader arguments - something you'll fetch these from cmdprmt\n","dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n","\n","# train dataloader\n","train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n","\n","# test dataloader\n","test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA Available? True\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","metadata":{"id":"hdjCdyIqYGwD"},"source":["dropout_value = 0.05\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        #Input block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), padding=0, bias=False), #input -(28, 28, 1)  OUtput- (26, 26, 8) RF - (3x3)\n","            nn.ReLU(), \n","            nn.BatchNorm2d(8),\n","            nn.Dropout(dropout_value)\n","        ) \n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3,3), padding=0, bias=False), #input -(26, 26, 16)  OUtput- (24, 24, 32) RF - (5x5)\n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Dropout(dropout_value)\n","        )\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=0, bias=False), #input -(24, 24, 32)  OUtput- (22, 22, 64) RF - (7x7)\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        )\n","        self.pool1 = nn.MaxPool2d(2,2) #input -(22, 22, 64)  OUtput- (11, 11, 64) RF - (14x14)\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1,1), padding=0, bias=False), #input -(11, 11, 64)  OUtput- (11, 11, 32) RF - (14x14)\n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Dropout(dropout_value)\n","        )\n","\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=8, kernel_size=(3,3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(8),\n","            nn.Dropout(dropout_value)\n","        )\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.Dropout(dropout_value)\n","        )\n","\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(10),\n","            nn.Dropout(dropout_value)\n","        )\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(7,7), padding=0, bias=False),\n","            #nn.ReLU() #never\n","        )\n","        \n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        x = self.convblock7(x)\n","        x = self.convblock8(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xdydjYTZFyi3","executionInfo":{"status":"ok","timestamp":1635157970653,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rakasi Swati","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07085964486056869501"}},"outputId":"096de86e-84a8-44ca-fbf9-a637d56f0734"},"source":["#!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 26, 26]              72\n","              ReLU-2            [-1, 8, 26, 26]               0\n","       BatchNorm2d-3            [-1, 8, 26, 26]              16\n","           Dropout-4            [-1, 8, 26, 26]               0\n","            Conv2d-5            [-1, 8, 24, 24]             576\n","              ReLU-6            [-1, 8, 24, 24]               0\n","       BatchNorm2d-7            [-1, 8, 24, 24]              16\n","           Dropout-8            [-1, 8, 24, 24]               0\n","            Conv2d-9           [-1, 16, 22, 22]           1,152\n","             ReLU-10           [-1, 16, 22, 22]               0\n","      BatchNorm2d-11           [-1, 16, 22, 22]              32\n","          Dropout-12           [-1, 16, 22, 22]               0\n","        MaxPool2d-13           [-1, 16, 11, 11]               0\n","           Conv2d-14            [-1, 8, 11, 11]             128\n","             ReLU-15            [-1, 8, 11, 11]               0\n","      BatchNorm2d-16            [-1, 8, 11, 11]              16\n","          Dropout-17            [-1, 8, 11, 11]               0\n","           Conv2d-18              [-1, 8, 9, 9]             576\n","             ReLU-19              [-1, 8, 9, 9]               0\n","      BatchNorm2d-20              [-1, 8, 9, 9]              16\n","          Dropout-21              [-1, 8, 9, 9]               0\n","           Conv2d-22             [-1, 16, 7, 7]           1,152\n","             ReLU-23             [-1, 16, 7, 7]               0\n","      BatchNorm2d-24             [-1, 16, 7, 7]              32\n","          Dropout-25             [-1, 16, 7, 7]               0\n","           Conv2d-26             [-1, 10, 7, 7]             160\n","             ReLU-27             [-1, 10, 7, 7]               0\n","      BatchNorm2d-28             [-1, 10, 7, 7]              20\n","          Dropout-29             [-1, 10, 7, 7]               0\n","           Conv2d-30             [-1, 10, 1, 1]           4,900\n","================================================================\n","Total params: 8,864\n","Trainable params: 8,864\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.65\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.68\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"SvUZIj2npINi"},"source":["from tqdm import tqdm\n","\n","train_losses = []\n","test_losses = []\n","train_acc = []\n","test_acc = []\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","  model.train()\n","  pbar = tqdm(train_loader)\n","  correct = 0\n","  processed = 0\n","  for batch_idx, (data, target) in enumerate(pbar):\n","    # get samples\n","    data, target = data.to(device), target.to(device)\n","\n","    # Init\n","    optimizer.zero_grad()\n","    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n","    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n","\n","    # Predict\n","    y_pred = model(data)\n","\n","    # Calculate loss\n","    loss = F.nll_loss(y_pred, target)\n","    train_losses.append(loss)\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Update pbar-tqdm\n","    \n","    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","    correct += pred.eq(target.view_as(pred)).sum().item()\n","    processed += len(data)\n","\n","    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n","    train_acc.append(100*correct/processed)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_losses.append(test_loss)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    \n","    test_acc.append(100. * correct / len(test_loader.dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635158291727,"user_tz":-330,"elapsed":317389,"user":{"displayName":"Rakasi Swati","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07085964486056869501"}},"outputId":"2e77ad99-b60a-4039-c270-4e764715947a"},"source":["from torch.optim.lr_scheduler import StepLR\n","\n","model =  Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n","\n","\n","EPOCHS = 15\n","for epoch in range(EPOCHS):\n","    print(\"EPOCH:\", epoch)\n","    train(model, device, train_loader, optimizer, epoch)\n","    # scheduler.step()\n","    test(model, device, test_loader)\n","\n","torch.manual_seed(1)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH: 0\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Loss=0.03303862735629082 Batch_id=468 Accuracy=94.23: 100%|██████████| 469/469 [00:18<00:00, 25.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0592, Accuracy: 9824/10000 (98.24%)\n","\n","EPOCH: 1\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.02541390061378479 Batch_id=468 Accuracy=98.08: 100%|██████████| 469/469 [00:18<00:00, 25.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0442, Accuracy: 9867/10000 (98.67%)\n","\n","EPOCH: 2\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.061872709542512894 Batch_id=468 Accuracy=98.47: 100%|██████████| 469/469 [00:18<00:00, 25.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0381, Accuracy: 9875/10000 (98.75%)\n","\n","EPOCH: 3\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.07232341915369034 Batch_id=468 Accuracy=98.58: 100%|██████████| 469/469 [00:18<00:00, 24.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0316, Accuracy: 9902/10000 (99.02%)\n","\n","EPOCH: 4\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.015348670072853565 Batch_id=468 Accuracy=98.69: 100%|██████████| 469/469 [00:18<00:00, 24.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0311, Accuracy: 9898/10000 (98.98%)\n","\n","EPOCH: 5\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.01640036515891552 Batch_id=468 Accuracy=98.84: 100%|██████████| 469/469 [00:18<00:00, 24.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0300, Accuracy: 9900/10000 (99.00%)\n","\n","EPOCH: 6\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.011209465563297272 Batch_id=468 Accuracy=98.99: 100%|██████████| 469/469 [00:18<00:00, 24.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0291, Accuracy: 9893/10000 (98.93%)\n","\n","EPOCH: 7\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.010042057372629642 Batch_id=468 Accuracy=98.93: 100%|██████████| 469/469 [00:18<00:00, 25.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0281, Accuracy: 9901/10000 (99.01%)\n","\n","EPOCH: 8\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.023122070357203484 Batch_id=468 Accuracy=99.08: 100%|██████████| 469/469 [00:18<00:00, 25.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0270, Accuracy: 9908/10000 (99.08%)\n","\n","EPOCH: 9\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.012231738306581974 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:18<00:00, 25.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0248, Accuracy: 9911/10000 (99.11%)\n","\n","EPOCH: 10\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.015550614334642887 Batch_id=468 Accuracy=99.10: 100%|██████████| 469/469 [00:18<00:00, 24.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0269, Accuracy: 9906/10000 (99.06%)\n","\n","EPOCH: 11\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.03363039717078209 Batch_id=468 Accuracy=99.16: 100%|██████████| 469/469 [00:18<00:00, 24.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0237, Accuracy: 9911/10000 (99.11%)\n","\n","EPOCH: 12\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.01119307428598404 Batch_id=468 Accuracy=99.21: 100%|██████████| 469/469 [00:18<00:00, 24.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0243, Accuracy: 9918/10000 (99.18%)\n","\n","EPOCH: 13\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.031919900327920914 Batch_id=468 Accuracy=99.22: 100%|██████████| 469/469 [00:18<00:00, 24.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0264, Accuracy: 9911/10000 (99.11%)\n","\n","EPOCH: 14\n"]},{"output_type":"stream","name":"stderr","text":["Loss=0.011168242432177067 Batch_id=468 Accuracy=99.26: 100%|██████████| 469/469 [00:18<00:00, 24.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0285, Accuracy: 9906/10000 (99.06%)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"qst-PpZN3CR-"},"source":[""],"execution_count":null,"outputs":[]}]}